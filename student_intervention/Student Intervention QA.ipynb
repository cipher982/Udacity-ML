{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Supervised Learning\n",
    "### Building a Student Intervention System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classification vs Regression\n",
    "\n",
    "Your goal is to identify students who might need early intervention - which type of supervised machine learning problem is this, classification or regression? Why?\n",
    "\n",
    "#### ANSWER:\n",
    "  Classification, as our target value is just a binary of Pass or Fail. Classification is suited to situations where you have discrete categorical values you are trying to predict, while Regression is designed for working with continuous numbers, such as the pricing of houses from our last project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploring the Data\n",
    "\n",
    "Let's go ahead and read in the student dataset first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, can you find out the following facts about the dataset?\n",
    "- Total number of students\n",
    "- Number of students who passed\n",
    "- Number of students who failed\n",
    "- Graduation rate of the class (%)\n",
    "- Number of features\n",
    "\n",
    "_Use the code block below to compute these values. Instructions/steps are marked using **TODO**s._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of students: 395\n",
      "Number of students who passed: 265\n",
      "Number of students who failed: 130\n",
      "Number of features: 30\n",
      "Graduation rate of the class: 67.09%\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compute desired values - replace each '?' with an appropriate expression/function call\n",
    "n_students = np.shape(student_data)[0]\n",
    "n_features = np.shape(student_data)[1] - 1 # Subtract target column\n",
    "n_passed = np.shape(student_data[student_data['passed']=='yes'])[0]\n",
    "n_failed = np.shape(student_data[student_data['passed']=='no'])[0]\n",
    "grad_rate = float(n_passed) / float(n_students)*100\n",
    "print \"Total number of students: {}\".format(n_students)\n",
    "print \"Number of students who passed: {}\".format(n_passed)\n",
    "print \"Number of students who failed: {}\".format(n_failed)\n",
    "print \"Number of features: {}\".format(n_features)\n",
    "print \"Graduation rate of the class: {:.2f}%\".format(grad_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess feature columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training and Evaluating Models\n",
    "Choose 3 supervised learning models that are available in scikit-learn, and appropriate for this problem. For each model:\n",
    "\n",
    "### - What are the general applications of this model? What are its strengths and weaknesses?\n",
    "#### Answer:\n",
    "##### Logistic Regression:\n",
    "  Used to predict caterogical outcomes of a binary result, this is a common and simple to use algorithm that is also fast to train and predict, which can be important when you have limited or costly computing power. Downsides can include a lack of correct predictions compared to more complex models, and it may need a larger dataset than other models to begin getting sufficient accuracy.\n",
    "    \n",
    "#### Decision Trees:\n",
    "  Another way of predicting an outcome, these are very easy to understand by a human just by plotting out the trained model and observing which traits go down which paths, and it is relatively quick to train and predict (even quicker than the logistic regression on this project).\n",
    "  But they can be prone to overfitting. As it has to choose path A or B for example, if path A is only slightly better (but both work) it will stick the results on on path A, as it lacks the probabilistic abilities of other models. Some of this can be solved by creating forests and pruning if this becomes a problem.\n",
    "\n",
    "#### Gradient Boosting\n",
    "  This is a sort of derivative of decision trees, whereas it attempts to build an ensemble of models, and give extra predictive power to each subsuquent models strengths, while downplaying the weaknesses. Though it can be a bit more complex than the two preceeding models, it has the ability to increase the amount of correct predictions by creating deeper learning models with the multitude of sequential trees created.\n",
    "  Unfortunately it can be hard to get the model set up correctly for each problem, as there are multiple parameters to tune before you begin to train. To solve this you could use a grid search to help select the best parameters. It also can be computationally expensive, as my results below show, it took the longest to train.\n",
    "\n",
    "\n",
    "### - Given what you know about the data so far, why did you choose this model to apply?\n",
    "\n",
    "#### Answer:\n",
    "##### Logistic Regression:\n",
    "  Given it's ease of use and simplcity, it made sense to start out with this to get a benchmark of performance against some of the other models, as we only need to predict Pass/Fail it seems to be a good match for this type of problem.\n",
    "    \n",
    "#### Decision Trees:\n",
    "  These are very simple to explain and understand, and are also computationally cheap which is important for this project. It can create a simple model tree for prediction of whether or not a student will pass, though I do understand they can be prone to overfitting unless some extra work is done such as ensembling or pruning.\n",
    "\n",
    "#### Gradient Boosting\n",
    "  I decided to throw in a slightly more complex model to see if it would have some clear benefits over the others. It has the potential to get the most correct predictions judged by F<sub>1</sub> score, though it does take a bit more computational work to train these models, and has many parameters you may need to tune to get it to run optimally\n",
    "\n",
    "### TODO:\n",
    "Produce a table showing training time, prediction time, F<sub>1</sub> score on training set and F<sub>1</sub> score on test set, for each training set size.\n",
    "\n",
    "Note: You need to produce 3 such tables - one for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training set size:</th>\n",
       "      <th>100</th>\n",
       "      <th>200</th>\n",
       "      <th>300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training time (secs)</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prediction time (secs)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F1 score for training set</td>\n",
       "      <td>0.90683</td>\n",
       "      <td>0.86598</td>\n",
       "      <td>0.83105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 score for test set</td>\n",
       "      <td>0.75912</td>\n",
       "      <td>0.788321</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Training set size:      100       200      300\n",
       "0       Training time (secs)    0.003     0.003    0.005\n",
       "1     Prediction time (secs)      0.0     0.001    0.001\n",
       "2  F1 score for training set  0.90683   0.86598  0.83105\n",
       "3      F1 score for test set  0.75912  0.788321      0.8"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogRegTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training set size:</th>\n",
       "      <th>100</th>\n",
       "      <th>200</th>\n",
       "      <th>300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training time (secs)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prediction time (secs)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F1 score for training set</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 score for test set</td>\n",
       "      <td>0.74419</td>\n",
       "      <td>0.70967</td>\n",
       "      <td>0.650407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Training set size:      100      200       300\n",
       "0       Training time (secs)     0.01    0.002     0.003\n",
       "1     Prediction time (secs)      0.0      0.0       0.0\n",
       "2  F1 score for training set      1.0      1.0       1.0\n",
       "3      F1 score for test set  0.74419  0.70967  0.650407"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecTreeTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training set size:</th>\n",
       "      <th>100</th>\n",
       "      <th>200</th>\n",
       "      <th>300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training time (secs)</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prediction time (secs)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F1 score for training set</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99281</td>\n",
       "      <td>0.975728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 score for test set</td>\n",
       "      <td>0.78519</td>\n",
       "      <td>0.761194</td>\n",
       "      <td>0.821439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Training set size:      100       200       300\n",
       "0       Training time (secs)    0.078     0.109     0.136\n",
       "1     Prediction time (secs)    0.001     0.001       0.0\n",
       "2  F1 score for training set      1.0   0.99281  0.975728\n",
       "3      F1 score for test set  0.78519  0.761194  0.821439"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GradBoostTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Choosing the Best Model\n",
    "\n",
    "### Question:\n",
    "#### - Based on the experiments you performed earlier, in 1-2 paragraphs explain to the board of supervisors what single model you chose as the best model. Which model is generally the most appropriate based on the available data, limited resources, cost, and performance?\n",
    "### Answer:\n",
    "  As we can see with the data *Logistic Regression* seems to hover right at or slightly above 80% accuracy, depending on the training size and other parameters. While it seems *Gradient Descent* was able to go slightly higher, at 82% with a training size of 300, it does not seem to offer enough of a benefit to be worth the extra computing cost. Gradient Boosting takes approcimately twice as long to calculate (.132s vs .07s), and though while the current training size is small and runs relatively fast on today's machines, if we were ever to expand the program the performance speed could become a bigger issue. \n",
    "\n",
    "  So that's why my current reccomendation is just to stay with regular Logistic Regression. It is a simple to understand way of modeling, and performs very quickly even if we scale up to larger datasets in the future.\n",
    "\n",
    "\n",
    "### Question:\n",
    "#### - In 1-2 paragraphs explain to the board of supervisors in layman's terms how the final model chosen is supposed to work (for example if you chose a Decision Tree or Support Vector Machine, how does it make a prediction).\n",
    "### Answer:\n",
    "  Logistic Regression is fairly easy to understand when you break it down. It is a derivate of the **Linear Regression** model that you commonly encounter in early level statistics or finance courses. To give a refresher, Linear Regression allows you to plot the relationship of two variables, one being independent (X-axis) and the other (Y-axis) being dependent upon that first value. An example could be the price of a home *(dependent, Y-axis)* being predicted by the square footage *(independent, X-axis).*\n",
    "  \n",
    "  You begin by plotting the datapoints of our current known information *(such as the square footage and selling price of previous homes)*, and then draw a best-fit line through the datapoints that minimizes the differences in y-values from the line to the points themselves. This line is created by the regression formula.\n",
    "    \n",
    "  Taking this another step forward to **logistic regression**, the y-axis values are now binary from 0 to 1. We are now **classifying the output** rather than finding a number. All the *Pass* students go at the very top of the y-axis, and all the *Fail* students go at the bottom of the y-axis. So we now fit a curved s-shaped line to plot a training model, using the information about previous students and whether they passed or failed. Then we can use that model to predict whether future students are more likely to pass or fail, depending on which side of the line we plotted their datapoint rests.\n",
    "    \n",
    "\n",
    "### TODO:\n",
    "#### - Fine-tune the model. Use Gridsearch with at least one important parameter tuned and with at least 3 settings. Use the entire training set for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Training set size: 300\n",
      "Training GridSearchCV...\n",
      "Done!\n",
      "Training time (secs): 0.369\n",
      "Predicting labels using GridSearchCV...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for training set: 0.802395209581\n",
      "Predicting labels using GridSearchCV...\n",
      "Done!\n",
      "Prediction time (secs): 0.000\n",
      "F1 score for test set: 0.805031446541\n"
     ]
    }
   ],
   "source": [
    "# TODO: Fine-tune your model and report the best F1 score\n",
    "from sklearn import grid_search\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "f1_scorer = make_scorer(f1_score, pos_label=\"yes\")\n",
    "\n",
    "\n",
    "# Set the parameters to search, Logistic Regression is relatively simple, not many parameters\n",
    "myparameters = {'C': [0.0001, 0.001, 0.01,0.05, 0.1,0.5, 1,5, 10, 100, 500,1000, 10000] }\n",
    "clf = grid_search.GridSearchCV(LogisticRegression(penalty='l2'), scoring = f1_scorer, param_grid = myparameters)\n",
    "\n",
    "train_predict(clf, X_train_300, y_train_300, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### - What is the model's final F<sub>1</sub> score?\n",
    "\n",
    "#### Answer:\n",
    "\n",
    "  After tuning for possible parameter values, I am only able to obtain an 80.5% F<sub>1</sub> score. Which is just slightly higher than what the model was able to get before the grid search, at 80%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
